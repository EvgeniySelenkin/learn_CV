{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing all the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom tensorflow.keras.utils import Sequence, to_categorical, plot_model\nfrom tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, concatenate, Input, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T02:29:35.814966Z","iopub.execute_input":"2022-05-19T02:29:35.815527Z","iopub.status.idle":"2022-05-19T02:29:41.854167Z","shell.execute_reply.started":"2022-05-19T02:29:35.815491Z","shell.execute_reply":"2022-05-19T02:29:41.853475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/'\nimg = cv2.imread(path + 'original_images/001.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nmask = cv2.imread(path + 'label_images_semantic/001.png', cv2.IMREAD_GRAYSCALE)\n#mask = mask.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig, axs = plt.subplots(1, 2, figsize=(20, 10))\naxs[0].imshow(img)\naxs[1].imshow(mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:29:41.91956Z","iopub.execute_input":"2022-05-19T02:29:41.919851Z","iopub.status.idle":"2022-05-19T02:29:47.176802Z","shell.execute_reply.started":"2022-05-19T02:29:41.919821Z","shell.execute_reply":"2022-05-19T02:29:47.175429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Image Dimensions are: ', img.shape)\nprint('Label Dimensions are: ', mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:29:47.178082Z","iopub.execute_input":"2022-05-19T02:29:47.178884Z","iopub.status.idle":"2022-05-19T02:29:47.185085Z","shell.execute_reply.started":"2022-05-19T02:29:47.178844Z","shell.execute_reply":"2022-05-19T02:29:47.184399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare the Images\nX = []\nfor filename in sorted(os.listdir(path + 'original_images/')):\n    a = cv2.imread(path + 'original_images/' + filename)\n    a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n    a = cv2.resize(a, (256, 256))\n    a = a / 255\n    X.append(a)\n    \nX = np.array(X)\n\n# Prepare the Labels\nY = []\nfor filename in sorted(os.listdir(path + 'label_images_semantic/')):\n    a = cv2.imread(path + 'label_images_semantic/' + filename, cv2.IMREAD_GRAYSCALE)\n    a = cv2.resize(a, (256, 256))\n    Y.append(a)\n    \nY = np.array(Y)\nYc = to_categorical(Y)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:29:47.186694Z","iopub.execute_input":"2022-05-19T02:29:47.1871Z","iopub.status.idle":"2022-05-19T02:33:50.202599Z","shell.execute_reply.started":"2022-05-19T02:29:47.187067Z","shell.execute_reply":"2022-05-19T02:33:50.201808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(Yc.shape)\nfig, axs = plt.subplots(1, 2, figsize=(20, 10))\naxs[0].imshow(X[1])\naxs[1].imshow(Y[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:50.204617Z","iopub.execute_input":"2022-05-19T02:33:50.204857Z","iopub.status.idle":"2022-05-19T02:33:50.69739Z","shell.execute_reply.started":"2022-05-19T02:33:50.204824Z","shell.execute_reply":"2022-05-19T02:33:50.69666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image1 = X[-1]\ntest_label1 = Yc[-1]\ntest_image2 = X[-2]\ntest_label2 = Yc[-2]\nx_train, x_val, y_train, y_val = train_test_split(X[0:-2], Yc[0:-2], test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:50.698406Z","iopub.execute_input":"2022-05-19T02:33:50.698749Z","iopub.status.idle":"2022-05-19T02:33:51.599035Z","shell.execute_reply.started":"2022-05-19T02:33:50.698718Z","shell.execute_reply":"2022-05-19T02:33:51.598261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:51.6002Z","iopub.execute_input":"2022-05-19T02:33:51.60078Z","iopub.status.idle":"2022-05-19T02:33:51.607015Z","shell.execute_reply.started":"2022-05-19T02:33:51.60074Z","shell.execute_reply":"2022-05-19T02:33:51.606254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(20, 10))\naxs[0].imshow(x_train[50])\naxs[1].imshow(np.argmax(y_train[50], axis=2))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:51.608191Z","iopub.execute_input":"2022-05-19T02:33:51.608999Z","iopub.status.idle":"2022-05-19T02:33:52.093952Z","shell.execute_reply.started":"2022-05-19T02:33:51.608962Z","shell.execute_reply":"2022-05-19T02:33:52.093319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet(num_classes = 23, image_shape = (256, 256, 3)):\n    # Input\n    inputs = Input(image_shape)\n    # Encoder Path\n    conv1 = Conv2D(64, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv1)\n    pool1 = MaxPooling2D((2,2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv2)\n    pool2 = MaxPooling2D((2,2))(conv2)\n\n    conv3 = Conv2D(256, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv3)\n    pool3 = MaxPooling2D((2,2))(conv3)\n    \n    conv4 = Conv2D(512, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool3)\n    conv4 = Conv2D(512, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D((2,2))(drop4)\n    \n    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool4)\n    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n    \n    # Decoder Path\n    up6 = Conv2D(512, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(drop5))\n    merge6 = concatenate([up6, conv4], axis = 3)\n    conv6 = Conv2D(512, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge6)\n    conv6 = Conv2D(512, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n    \n    up7 = Conv2D(256, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv6))\n    merge7 = concatenate([up7, conv3], axis = 3)\n    conv7 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge7)\n    conv7 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n    \n    up8 = Conv2D(128, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv7))\n    merge8 = concatenate([up8, conv2], axis = 3)\n    conv8 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge8)\n    conv8 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n    \n    up9 = Conv2D(64, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv8))\n    merge9 = concatenate([up9, conv1], axis = 3)\n    conv9 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge9)\n    conv9 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n    \n    conv10 = Conv2D(num_classes, (1, 1), padding='same', activation='softmax')(conv9)\n    \n    model = Model(inputs, conv10)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:52.095466Z","iopub.execute_input":"2022-05-19T02:33:52.095864Z","iopub.status.idle":"2022-05-19T02:33:52.121762Z","shell.execute_reply.started":"2022-05-19T02:33:52.095827Z","shell.execute_reply":"2022-05-19T02:33:52.120959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:52.123144Z","iopub.execute_input":"2022-05-19T02:33:52.1238Z","iopub.status.idle":"2022-05-19T02:33:55.503827Z","shell.execute_reply.started":"2022-05-19T02:33:52.123763Z","shell.execute_reply":"2022-05-19T02:33:55.502998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:55.506682Z","iopub.execute_input":"2022-05-19T02:33:55.506931Z","iopub.status.idle":"2022-05-19T02:33:56.729409Z","shell.execute_reply.started":"2022-05-19T02:33:55.506894Z","shell.execute_reply":"2022-05-19T02:33:56.727787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('unet_model.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\nmodel_earlyStopping = EarlyStopping(min_delta= 0.001, patience=30)\n\nmodel.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n\nhistory_1 = model.fit(x=x_train, y=y_train,\n              validation_data=(x_val, y_val),\n              batch_size=16, epochs=20,\n              callbacks=[model_checkpoint, model_earlyStopping])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:33:56.731599Z","iopub.execute_input":"2022-05-19T02:33:56.732186Z","iopub.status.idle":"2022-05-19T02:39:24.729302Z","shell.execute_reply.started":"2022-05-19T02:33:56.732144Z","shell.execute_reply":"2022-05-19T02:39:24.72758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history_1.history['accuracy']\nval_acc = history_1.history['val_accuracy']\nloss = history_1.history['loss']\nval_loss = history_1.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:39:24.732533Z","iopub.execute_input":"2022-05-19T02:39:24.733849Z","iopub.status.idle":"2022-05-19T02:39:25.094588Z","shell.execute_reply.started":"2022-05-19T02:39:24.733798Z","shell.execute_reply":"2022-05-19T02:39:25.093852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = test_image1\npred = model.predict(np.expand_dims(m1, 0))\npred_mask = np.argmax(pred, axis=-1)\nprint(pred_mask.shape)\npred_mask = pred_mask[0]\nprint(pred_mask.shape)\n\nm2 = test_image2\npred2 = model.predict(np.expand_dims(m2, 0))\npred_mask2 = np.argmax(pred2, axis=-1)\nprint(pred_mask2.shape)\npred_mask2 = pred_mask2[0]\nprint(pred_mask2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:39:25.095825Z","iopub.execute_input":"2022-05-19T02:39:25.096393Z","iopub.status.idle":"2022-05-19T02:39:26.140632Z","shell.execute_reply.started":"2022-05-19T02:39:25.09635Z","shell.execute_reply":"2022-05-19T02:39:26.139847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20, 10))\naxs[0].imshow(m1)\naxs[0].set_title('Image')\naxs[1].imshow(np.argmax(test_label1, axis=-1))\naxs[1].set_title('Ground Truth')\naxs[2].imshow(pred_mask)\naxs[2].set_title('Prediction')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:39:26.141752Z","iopub.execute_input":"2022-05-19T02:39:26.142202Z","iopub.status.idle":"2022-05-19T02:39:26.623544Z","shell.execute_reply.started":"2022-05-19T02:39:26.142162Z","shell.execute_reply":"2022-05-19T02:39:26.622869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20, 10))\naxs[0].imshow(m2)\naxs[0].set_title('Image')\naxs[1].imshow(np.argmax(test_label2, axis=-1))\naxs[1].set_title('Ground Truth')\naxs[2].imshow(pred_mask2)\naxs[2].set_title('Prediction')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T02:39:26.624558Z","iopub.execute_input":"2022-05-19T02:39:26.62493Z","iopub.status.idle":"2022-05-19T02:39:27.122801Z","shell.execute_reply.started":"2022-05-19T02:39:26.624886Z","shell.execute_reply":"2022-05-19T02:39:27.121863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet_2(num_classes = 23, image_shape = (256, 256, 3)):\n    # Input\n    inputs = Input(image_shape)\n    # Encoder Path\n    conv1 = Conv2D(64, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv1)\n    pool1 = MaxPooling2D((2,2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv2)\n    pool2 = MaxPooling2D((2,2))(conv2)\n\n    conv3 = Conv2D(256, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv3)\n    pool3 = MaxPooling2D((2,2))(conv3)\n    \n    # Decoder Path\n    up6 = Conv2D(256, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(pool3))\n    merge6 = concatenate([up6, conv3], axis = 3)\n    conv6 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge6)\n    conv6 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n    \n    up8 = Conv2D(128, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv6))\n    merge8 = concatenate([up8, conv2], axis = 3)\n    conv8 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge8)\n    conv8 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n    \n    up9 = Conv2D(64, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv8))\n    merge9 = concatenate([up9, conv1], axis = 3)\n    conv9 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge9)\n    conv9 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n    \n    conv10 = Conv2D(num_classes, (1, 1), padding='same', activation='softmax')(conv9)\n    \n    model = Model(inputs, conv10)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:46:19.326567Z","iopub.execute_input":"2022-05-18T20:46:19.326829Z","iopub.status.idle":"2022-05-18T20:46:19.343028Z","shell.execute_reply.started":"2022-05-18T20:46:19.326793Z","shell.execute_reply":"2022-05-18T20:46:19.342153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet_2()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:46:21.292743Z","iopub.execute_input":"2022-05-18T20:46:21.293166Z","iopub.status.idle":"2022-05-18T20:46:21.437662Z","shell.execute_reply.started":"2022-05-18T20:46:21.29313Z","shell.execute_reply":"2022-05-18T20:46:21.436958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('unet_model.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\nmodel_earlyStopping = EarlyStopping(min_delta= 0.001, patience=30)\n\nmodel.compile(optimizer='rmsprop', loss=['categorical_crossentropy'], metrics=['accuracy'])\n\nhistory_2 = model.fit(x=x_train, y=y_train,\n              validation_data=(x_val, y_val),\n              batch_size=16, epochs=20,\n              callbacks=[model_checkpoint, model_earlyStopping])","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:47:00.574285Z","iopub.execute_input":"2022-05-18T20:47:00.57471Z","iopub.status.idle":"2022-05-18T20:50:40.732137Z","shell.execute_reply.started":"2022-05-18T20:47:00.574667Z","shell.execute_reply":"2022-05-18T20:50:40.729884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import BatchNormalization, Activation, SeparableConv2D, add, Conv2DTranspose\nfrom tensorflow.keras.backend import clear_session","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:35:07.96666Z","iopub.execute_input":"2022-05-18T20:35:07.967123Z","iopub.status.idle":"2022-05-18T20:35:07.972437Z","shell.execute_reply.started":"2022-05-18T20:35:07.967081Z","shell.execute_reply":"2022-05-18T20:35:07.97179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history_2.history['accuracy']\nval_acc = history_2.history['val_accuracy']\nloss = history_2.history['loss']\nval_loss = history_2.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:50:40.734014Z","iopub.execute_input":"2022-05-18T20:50:40.734358Z","iopub.status.idle":"2022-05-18T20:50:41.156884Z","shell.execute_reply.started":"2022-05-18T20:50:40.734318Z","shell.execute_reply":"2022-05-18T20:50:41.156227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = test_image1\npred = model.predict(np.expand_dims(m1, 0))\npred_mask = np.argmax(pred, axis=-1)\nprint(pred_mask.shape)\npred_mask = pred_mask[0]\nprint(pred_mask.shape)\n\nm2 = test_image2\npred2 = model.predict(np.expand_dims(m2, 0))\npred_mask2 = np.argmax(pred2, axis=-1)\nprint(pred_mask2.shape)\npred_mask2 = pred_mask2[0]\nprint(pred_mask2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:50:41.158252Z","iopub.execute_input":"2022-05-18T20:50:41.158509Z","iopub.status.idle":"2022-05-18T20:50:42.287566Z","shell.execute_reply.started":"2022-05-18T20:50:41.158474Z","shell.execute_reply":"2022-05-18T20:50:42.286773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20, 10))\naxs[0].imshow(m1)\naxs[0].set_title('Image')\naxs[1].imshow(np.argmax(test_label1, axis=-1))\naxs[1].set_title('Ground Truth')\naxs[2].imshow(pred_mask)\naxs[2].set_title('Prediction')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:50:42.289336Z","iopub.execute_input":"2022-05-18T20:50:42.28956Z","iopub.status.idle":"2022-05-18T20:50:42.733602Z","shell.execute_reply.started":"2022-05-18T20:50:42.289533Z","shell.execute_reply":"2022-05-18T20:50:42.732924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20, 10))\naxs[0].imshow(m2)\naxs[0].set_title('Image')\naxs[1].imshow(np.argmax(test_label2, axis=-1))\naxs[1].set_title('Ground Truth')\naxs[2].imshow(pred_mask2)\naxs[2].set_title('Prediction')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T20:50:42.73497Z","iopub.execute_input":"2022-05-18T20:50:42.73542Z","iopub.status.idle":"2022-05-18T20:50:43.176469Z","shell.execute_reply.started":"2022-05-18T20:50:42.735384Z","shell.execute_reply":"2022-05-18T20:50:43.175114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}